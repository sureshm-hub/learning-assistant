# ğŸ“š Personalized Learning Assistant

**A Retrieval-Augmented Generation (RAG) AI-powered learning assistant that answers educational queries using curated study materials.**

---

## ğŸš€ Features
- **Retrieval-Augmented Generation (RAG):** Enhances responses with relevant context from study materials.
- **FastAPI Backend:** Handles AI query processing and vector search.
- **Streamlit UI:** Simple web-based chatbot interface for asking questions.
- **FAISS Vector Store:** Efficient similarity search for retrieving relevant content.
- **Modular Architecture:** Separate components for ingestion, backend, and UI.

---

## ğŸ“‚ Project Structure
```
learning-assistant/
â”‚â”€â”€ ingestion/          # Data ingestion & embedding storage
â”‚   â”œâ”€â”€ data_ingestion.py   # Script to load, split, and store embeddings
â”‚   â”œâ”€â”€ study_material.txt  # Sample study material (text file)
â”‚   â”œâ”€â”€ vector_store/       # Folder to store FAISS index
â”‚
â”‚â”€â”€ backend/           # API & business logic
â”‚   â”œâ”€â”€ main.py          # FastAPI backend
â”‚   â”œâ”€â”€ requirements.txt # Backend dependencies
â”‚   â”œâ”€â”€ config.py        # Configuration settings
â”‚
â”‚â”€â”€ ui/                # User interface (Streamlit frontend)
â”‚   â”œâ”€â”€ app.py          # Streamlit UI
â”‚   â”œâ”€â”€ assets/         # UI assets (images, icons, etc.)
â”‚
â”‚â”€â”€ env/               # Virtual environment (not committed to Git)
â”‚â”€â”€ .env               # API keys & environment variables
â”‚â”€â”€ .gitignore         # Ignore unnecessary files
â”‚â”€â”€ README.md          # Documentation
```

---

## ğŸ› ï¸ Installation & Setup
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/learning-assistant.git
cd learning-assistant
```

### **2ï¸âƒ£ Set Up Virtual Environment**
```bash
python -m venv env
source env/bin/activate  # Windows: env\Scripts\activate
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r backend/requirements.txt
pip install -r ui/requirements.txt
```

### **4ï¸âƒ£ Generate Study Material Embeddings**
```bash
cd ingestion
python data_ingestion.py
```

### **5ï¸âƒ£ Start Backend (FastAPI)**
```bash
cd ../backend
uvicorn main:app --reload
```

### **6ï¸âƒ£ Start UI (Streamlit)**
```bash
cd ../ui
streamlit run app.py
```

---

## ğŸ” Usage
- **Ask a question** through the Streamlit interface.
- The system retrieves **relevant study material** from FAISS.
- The AI generates an answer **strictly based on study material** (to prevent hallucination).

---

## ğŸ›  Tech Stack
- **Frontend:** Streamlit
- **Backend:** FastAPI
- **Vector Store:** FAISS
- **LLM:** OpenAI GPT-4 (or LLaMA/Mistral)
- **Embeddings:** OpenAI's `text-embedding-ada-002`

---

## ğŸ“Œ Example Queries
### âœ… **Valid Queries (Covered in Study Material)**
- *What is supervised learning?*
- *Explain reinforcement learning with an example.*
- *How does a decision tree work?*

### âŒ **Negative Test Cases (Out-of-Scope Queries)**
- *Who discovered the theory of relativity?* (Not in study material)
- *Explain the history of blockchain.* (Irrelevant to ML topics)
- *What are the latest AI trends?* (Not covered in study material)

---

## ğŸ“œ License
This project is open-source and available under the **MIT License**.

---

## ğŸ¤ Contributing
Feel free to fork this repository, submit issues, or create pull requests to enhance functionality!